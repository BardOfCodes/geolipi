{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "#### This is mostly deprecated. My current thinking is that if you have a specific optimization task, you can get better bang for your buck with an application specific evaluator (when considering time). Nonetheless, here we can see some general usage pattern for differentiable optimization of the primitives. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing 2D GeoLIPI programs\n",
    "Since GeoLIPI programs are parameterized using pyTorch, we can optimize them with pytorch's auto-grad and gradient based optimizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 2D CSG\n",
    "import os\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import geolipi.symbolic as gls\n",
    "import cv2\n",
    "from geolipi.torch_compute import expr_to_sdf, recursive_evaluate\n",
    "from geolipi.torch_compute import Sketcher\n",
    "from geolipi.torch_compute.evaluate_expression import _smoothen_sdf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 256\n",
    "sketcher_2d = Sketcher(resolution=resolution, n_dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSVG example of line Opt - without correspondence/SVG GT.\n",
    "# load target\n",
    "target = cv2.imread(\"../assets/dolphin_points.png\", cv2.IMREAD_GRAYSCALE)\n",
    "# show target\n",
    "target = target[60:-60, 140:-140]\n",
    "# Rescale to 256\n",
    "target = cv2.resize(target, (resolution, resolution))\n",
    "print(target.shape)\n",
    "plt.imshow(target, cmap='gray')\n",
    "plt.axis('off')\n",
    "target_occ = target < 255\n",
    "target_occ = th.tensor(target_occ, dtype=th.float32, device=\"cuda\").reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now generate expression \n",
    "# Line approx\n",
    "def get_circle_points(radius=0.1, n_points=100, angle_delta=0.0):\n",
    "    n_points = n_points + 1\n",
    "    angles = np.linspace(0, 2*np.pi, n_points) + angle_delta\n",
    "    points = np.zeros((n_points, 2))\n",
    "    points[:, 0] = radius * np.cos(angles)\n",
    "    points[:, 1] = radius * np.sin(angles)\n",
    "    return points\n",
    "# sample points\n",
    "n_points = 32\n",
    "points = get_circle_points(0.7, n_points)\n",
    "tensor_points = th.tensor(points, device=\"cuda\", dtype=th.float32, requires_grad=True)\n",
    "subexpr = []\n",
    "for i in range(n_points):\n",
    "    expr = gls.Segment2D(tensor_points[i], tensor_points[(i+1)%n_points])\n",
    "    subexpr.append(expr)\n",
    "dil_tensor = th.tensor([0.03,], device=\"cuda\")\n",
    "expr = gls.Dilate2D(gls.Union(*subexpr), dil_tensor)\n",
    "\n",
    "# show the output\n",
    "# print(expr.pretty_print())\n",
    "sdf = recursive_evaluate(expr, sketcher_2d)\n",
    "# target_occ = (sdf <= 0.00).float()\n",
    "sdf = sdf.reshape(resolution, resolution).detach().cpu().numpy()\n",
    "occ = (sdf <= 0.00)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(sdf)\n",
    "plt.axis('off')\n",
    "plt.title(\"Sign Distance Field\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(occ, cmap='gray')\n",
    "plt.title(\"Occupancy\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the optimization loop:\n",
    "optim = th.optim.Adam([tensor_points], lr=0.005)\n",
    "n_iters  = 2048\n",
    "# The amount of \"smoothing\"\n",
    "t_vals = np.linspace(2, 15, n_iters)\n",
    "\n",
    "for i in range(n_iters):\n",
    "# for i in range(200):\n",
    "    optim.zero_grad()\n",
    "    # unpack tensor_points\n",
    "    # creating the list of tensors in inject into expression\n",
    "    tensor_list = []\n",
    "    for ind in range(n_points):\n",
    "        tensor_list.append(tensor_points[ind])\n",
    "        tensor_list.append(tensor_points[(ind + 1) % n_points])\n",
    "    tensor_list.append(dil_tensor)\n",
    "    cur_expr = expr.inject_tensor_list(tensor_list)\n",
    "    sdf = recursive_evaluate(cur_expr, sketcher_2d)\n",
    "    soft_sdf = _smoothen_sdf(sdf, t_vals[i])\n",
    "    loss = 0.5 * th.sum(((soft_sdf - target_occ)) ** 2)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if i % 200 == 0:\n",
    "        print(f\"SDF Loss: {loss.item()}, iter: {i}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = recursive_evaluate(cur_expr, sketcher_2d)\n",
    "soft_sdf = _smoothen_sdf(sdf, t_vals[i])\n",
    "soft_sdf = soft_sdf.reshape(resolution, resolution).detach().cpu().numpy()\n",
    "sdf = sdf.reshape(resolution, resolution).detach().cpu().numpy()\n",
    "occ = (sdf <= 0.00)\n",
    "target = target_occ.reshape(resolution, resolution).detach().cpu().numpy()\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.imshow(sdf)\n",
    "plt.axis('off')\n",
    "plt.title(\"Sign Distance Field\")\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.imshow(soft_sdf,)\n",
    "plt.title(\"Soft SDF\")\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.imshow(occ, cmap='gray')\n",
    "plt.title(\"Optimized Occupancy\")\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.imshow(target, cmap='gray')\n",
    "plt.title(\"Target\")\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now generate expression \n",
    "# sample points\n",
    "n_points = 32\n",
    "points = get_circle_points(0.7, n_points)\n",
    "mid_points = get_circle_points(0.7, n_points, angle_delta=np.pi/n_points)\n",
    "tensor_points = th.tensor(points, device=\"cuda\", dtype=th.float32, requires_grad=True)\n",
    "tensor_mid_points = th.tensor(mid_points, device=\"cuda\", dtype=th.float32, requires_grad=True)\n",
    "subexpr = []\n",
    "for i in range(n_points):\n",
    "    expr = gls.QuadraticBezierCurve2D(tensor_points[i], tensor_mid_points[i], tensor_points[(i+1)%n_points])\n",
    "    subexpr.append(expr)\n",
    "dil_tensor = th.tensor([0.2,], device=\"cuda\")\n",
    "expr = gls.Dilate2D(gls.Union(*subexpr), dil_tensor)\n",
    "\n",
    "# show the output\n",
    "# print(expr.pretty_print())\n",
    "sdf = recursive_evaluate(expr, sketcher_2d)\n",
    "# target_occ = (sdf <= 0.00).float()\n",
    "sdf = sdf.reshape(resolution, resolution).detach().cpu().numpy()\n",
    "occ = (sdf <= 0.00)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(sdf)\n",
    "plt.axis('off')\n",
    "plt.title(\"Sign Distance Field\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(occ, cmap='gray')\n",
    "plt.title(\"Occupancy\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DISP_THRESHOLD = 0.1\n",
    "def compute_point_overlap_loss(all_points):\n",
    "    all_points = tensor_points\n",
    "    n_p = all_points.shape[0]\n",
    "    all_points_a = all_points[:, None, :].expand(n_p, n_p, 2)\n",
    "    all_points_b = all_points[None, :, :].expand(n_p, n_p, 2)\n",
    "    all_points_dist = th.norm(all_points_a - all_points_b, dim=-1)\n",
    "    cur_loss = th.where(all_points_dist > DISP_THRESHOLD, th.zeros_like(all_points_dist), all_points_dist)\n",
    "    cur_loss = th.sum(cur_loss)\n",
    "    one_shifted = th.roll(all_points, 1, 0)\n",
    "    two_shifted = th.roll(all_points, 2, 0)\n",
    "    ab = one_shifted - all_points\n",
    "    bc = two_shifted - one_shifted\n",
    "    return cur_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plt_figure(cur_expr, sketcher_2d, cur_t_val, resolution):\n",
    "    sdf = recursive_evaluate(cur_expr, sketcher_2d)\n",
    "    occ = (sdf.clone() <= 0.00)\n",
    "    soft_sdf = _smoothen_sdf(sdf.clone(), cur_t_val)\n",
    "    sdf = sdf.reshape(resolution, resolution).detach().cpu().numpy()\n",
    "    soft_sdf = soft_sdf.reshape(resolution, resolution).detach().cpu().numpy()\n",
    "    target = target_occ.reshape(resolution, resolution).detach().cpu().numpy()\n",
    "    occ = occ.reshape(resolution, resolution).detach().cpu().numpy()\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.imshow(sdf)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Sign Distance Field\")\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.imshow(soft_sdf,)\n",
    "    plt.title(\"Soft Occupancy\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.imshow(occ, cmap='gray')\n",
    "    plt.title(\"Execution\")\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.imshow(target, cmap='gray')\n",
    "    plt.title(\"Target\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the optimization loop:\n",
    "\n",
    "optim = th.optim.Adam([tensor_points, tensor_mid_points], lr=0.005)\n",
    "n_iters  = 2048\n",
    "point_spread_loss_wt = 1.0\n",
    "# The amount of \"smoothing\"\n",
    "t_vals = np.linspace(2, 12, n_iters)\n",
    "\n",
    "for i in range(n_iters):\n",
    "    optim.zero_grad()\n",
    "    # unpack tensor_points\n",
    "    # creating the list of tensors\n",
    "    tensor_list = []\n",
    "    for ind in range(n_points):\n",
    "        tensor_list.append(tensor_points[ind])\n",
    "        tensor_list.append(tensor_mid_points[ind])\n",
    "        tensor_list.append(tensor_points[(ind+1)%n_points])\n",
    "    tensor_list.append(dil_tensor)\n",
    "    cur_expr = expr.inject_tensor_list(tensor_list)\n",
    "    sdf = recursive_evaluate(cur_expr, sketcher_2d)\n",
    "    cur_t_val = t_vals[i]\n",
    "    soft_sdf = _smoothen_sdf(sdf, cur_t_val)\n",
    "    sdf_diff = ((soft_sdf - target_occ)) ** 2\n",
    "    sdf_loss = 0.5 * th.sum(sdf_diff)\n",
    "    # Add a loss for lines endpoints not overlapping to 0?\n",
    "    point_overlap_loss = compute_point_overlap_loss(tensor_points)\n",
    "    loss = point_overlap_loss * point_spread_loss_wt + sdf_loss\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    # generate_plt_figure(cur_expr, sketcher_2d, cur_t_val, resolution)\n",
    "    # file_name = os.path.join(f'temp/{i}.png')\n",
    "    # plt.savefig(file_name, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    if i % 200 == 0:\n",
    "        print(f\"SDF Loss: {sdf_loss.item()}, Point_loss: {point_overlap_loss.item()}, iter: {i}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plt_figure(cur_expr, sketcher_2d, cur_t_val, resolution)\n",
    "plt.savefig(\"../assets/svg_optimization.png\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to gif\n",
    "import imageio\n",
    "file_names = [os.path.join(f'temp/{i}.png') for i in range(n_iters)]\n",
    "file_names = file_names[:1024]\n",
    "\n",
    "images = [imageio.imread(fn) for fn in file_names]\n",
    "imageio.mimsave('../assets/svg_path_opt.gif', images, fps=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 256\n",
    "sketcher_2d = Sketcher(resolution=resolution, n_dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Simple SVG\n",
    "# from geolipi.torch_compute import expr_to_colored_canvas\n",
    "# load target:\n",
    "target = cv2.imread(\"../assets/van_gogh.jpg\")\n",
    "# Convert to RGBA\n",
    "target = cv2.cvtColor(target, cv2.COLOR_BGR2RGBA)\n",
    "# show target\n",
    "target = target[150:-550]\n",
    "print(target.shape)\n",
    "target = cv2.resize(target, (resolution, resolution))\n",
    "plt.imshow(target)\n",
    "plt.axis('off')\n",
    "target = th.tensor(target, dtype=th.float32, device=\"cuda\").reshape(-1, 4)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_plt_figure(cur_expr, sketcher_2d, cur_t_val, resolution):\n",
    "    colored_canvas = recursive_evaluate(cur_expr, sketcher_2d)\n",
    "    colored_canvas = colored_canvas.reshape(resolution, resolution, 4).detach().cpu().numpy()\n",
    "    soft_canvas = recursive_evaluate(cur_expr, sketcher_2d, \n",
    "                                        relaxed_occupancy=True,\n",
    "                                        relax_temperature= cur_t_val)\n",
    "    soft_canvas = soft_canvas.reshape(resolution, resolution, 4).detach().cpu().numpy()\n",
    "    target_disp = target.reshape(resolution, resolution, 4).detach().cpu().numpy()\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(soft_canvas)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Soft Execution\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(colored_canvas)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Optimized Execution\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(target_disp)\n",
    "    plt.title(\"Target\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter a set of colored cubes and optimize their positions\n",
    "# to match a target image.\n",
    "n_rects = 64\n",
    "rect_param = np.random.uniform(0.2, 0.4, size=(n_rects, 1))\n",
    "\n",
    "rect_pos = np.random.uniform(-0.75, 0.75, size=(n_rects, 2))\n",
    "rect_param = th.tensor(rect_param, device=\"cuda\", dtype=th.float32, requires_grad=True)\n",
    "rect_pos = th.tensor(rect_pos, device=\"cuda\", dtype=th.float32, requires_grad=True)\n",
    "colors = np.random.uniform(0.0, 1.0, size=(n_rects, 4))\n",
    "colors[:, 3] = 0.95\n",
    "colors_pre = np.arctanh(2 * colors - 1)\n",
    "colors_pre = th.tensor(colors_pre, device=\"cuda\", dtype=th.float32, requires_grad=True)\n",
    "colors = (th.tanh(colors_pre) + 1) * 0.5\n",
    "rect_list = []\n",
    "for i in range(n_rects):\n",
    "    rectangle = gls.ApplyColor2D(gls.Translate2D(gls.Hexagram2D(rect_param[i]), rect_pos[i]), colors[i])\n",
    "    rect_list.append(rectangle)\n",
    "expr = gls.SourceOverSequence(*rect_list)\n",
    "# show the output\n",
    "colored_canvas = recursive_evaluate(expr, sketcher_2d, \n",
    "                                    relaxed_occupancy=True,\n",
    "                                    relax_temperature= 5.0,)\n",
    "colored_canvas = colored_canvas.reshape(resolution, resolution, 4).detach().cpu().numpy()\n",
    "plt.imshow(colored_canvas)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the optimization loop:\n",
    "\n",
    "optim = th.optim.Adam([rect_param, rect_pos, colors_pre], lr=0.005)\n",
    "n_iters  = 2048\n",
    "point_spread_loss_wt = 1.0\n",
    "# The amount of \"smoothing\"\n",
    "t_vals = np.linspace(np.log(np.log(4)), np.log(np.log(15)), n_iters)\n",
    "t_vals = np.exp((np.exp(t_vals)))\n",
    "alpha_range = np.linspace(0, 10, n_iters)\n",
    "alpha_range = alpha_range/100.0\n",
    "\n",
    "\n",
    "for i in range(n_iters):\n",
    "# for i in range(200):\n",
    "    optim.zero_grad()\n",
    "    # unpack tensor_points\n",
    "    # creating the list of tensors\n",
    "    tensor_list = []\n",
    "    colors = (th.tanh(colors_pre) + 1)\n",
    "    colors[:, :-1] = colors[:, :-1] * 0.5\n",
    "    colors[:, -1] = colors[:, -1] * (0.40 + alpha_range[i])\n",
    "\n",
    "    # t_ps = th.tanh(primal_points)\n",
    "    for ind in range(n_rects):\n",
    "        tensor_list.append(rect_param[ind])\n",
    "        tensor_list.append(rect_pos[ind])\n",
    "        tensor_list.append(colors[ind])\n",
    "    cur_expr = expr.inject_tensor_list(tensor_list)\n",
    "    cur_t_val = t_vals[i]\n",
    "    color_out = recursive_evaluate(cur_expr, sketcher_2d, \n",
    "                                    relaxed_occupancy=True,\n",
    "                                    relax_temperature= cur_t_val,)\n",
    "    color_diff = color_out - target\n",
    "    color_diff = th.norm(color_diff, dim=-1)\n",
    "    # Drop points stochastically\n",
    "    # point_overlap_loss = compute_point_overlap_loss(rect_pos)\n",
    "    # color_diff = th.nn.functional.dropout(color_diff, p=0.1, training=True)\n",
    "    color_loss = 0.5 * th.sum(color_diff)\n",
    "    ret_origin_dist = rect_pos.norm(dim=-1)\n",
    "    rect_pos_loss = th.sum(th.where(ret_origin_dist > 0.8, ret_origin_dist, th.zeros_like(ret_origin_dist)))\n",
    "    rect_sizes = rect_param[:, 0] #* rect_param[:, 1]\n",
    "    rect_size_loss = th.sum(th.where(rect_sizes < 0.25, -rect_sizes, th.zeros_like(rect_sizes)))\n",
    "    rect_size_loss_2 = th.sum(th.where(rect_sizes > .75, rect_sizes, th.zeros_like(rect_sizes)))\n",
    "\n",
    "    # Add a loss for lines endpoints not overlapping to 0?\n",
    "    # point_overlap_loss = compute_point_overlap_loss(tensor_points)\n",
    "    loss = color_loss  #+ 5000 * (rect_pos_loss + rect_size_loss + rect_size_loss_2)# + point_overlap_loss * point_spread_loss_wt\n",
    "    loss.backward()\n",
    "    # colors.grad[:, -1] = 0\n",
    "    generate_plt_figure(cur_expr, sketcher_2d, cur_t_val, resolution)\n",
    "    file_name = os.path.join(f'temp/{i}.png')\n",
    "    plt.savefig(file_name, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    optim.step()\n",
    "    if i % 25 == 0:\n",
    "        print(f\"Color Loss: {color_loss.item()}, pos_loss: {rect_pos_loss.item()}, size_loss: {rect_size_loss.item()}, iter: {i}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plt_figure(cur_expr, sketcher_2d, cur_t_val, resolution)\n",
    "plt.savefig(\"../assets/starry.png\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to gif\n",
    "import imageio\n",
    "n_iters = 2048\n",
    "file_names = [os.path.join(f'temp/{i}.png') for i in range(n_iters)]\n",
    "file_names = [x for ind, x in enumerate(file_names) if ind %4 ==0]\n",
    "\n",
    "images = [imageio.imread(fn) for fn in file_names]\n",
    "imageio.mimsave('../assets/starry.gif', images, fps=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Layer-wise optimization - LIVE style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 128 circles for starry night\n",
    "# from geolipi.torch_compute import expr_to_colored_canvas\n",
    "# load target:\n",
    "target = cv2.imread(\"../assets/Starry_Night.jpg\")\n",
    "# Convert to RGBA\n",
    "target = cv2.cvtColor(target, cv2.COLOR_BGR2RGBA)\n",
    "# show target\n",
    "target = target[:,0:-157]\n",
    "print(target.shape)\n",
    "resolution = 256\n",
    "target = cv2.resize(target, (resolution, resolution))\n",
    "plt.imshow(target)\n",
    "plt.axis('off')\n",
    "target = th.tensor(target, dtype=th.float32, device=\"cuda\").reshape(-1, 4)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prim_per_layer = 64\n",
    "n_layers = 1\n",
    "lr = 0.005\n",
    "n_iters = 2000\n",
    "t_min = 4\n",
    "t_max = 15\n",
    "TAU = 0.1\n",
    "\n",
    "t_vals = np.linspace(np.log(np.log(4)), np.log(np.log(15)), n_iters)\n",
    "t_vals = np.exp((np.exp(t_vals)))\n",
    "alpha_range = np.linspace(0, 10, n_iters)\n",
    "alpha_range = alpha_range/100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: SVG with UDF + Layerwise optimization\n",
    "\n",
    "# 1 loss is driven by sdf.\n",
    "\n",
    "# Scatter a set of colored cubes and optimize their positions\n",
    "# to match a target image.\n",
    "def generate_random_circles(n_circles):\n",
    "\n",
    "    circle_param = np.random.uniform(0.2, 0.5, size=(n_rects, 1))\n",
    "    circle_pos = np.random.uniform(-0.75, 0.75, size=(n_rects, 2))\n",
    "    circle_scale = np.random.uniform(0.25, 1.75, size=(n_rects, 2))\n",
    "\n",
    "    circle_param = th.tensor(circle_param, device=\"cuda\", dtype=th.float32, requires_grad=True)\n",
    "    circle_pos = th.tensor(circle_pos, device=\"cuda\", dtype=th.float32, requires_grad=True)\n",
    "    circle_scale = th.tensor(circle_scale, device=\"cuda\", dtype=th.float32, requires_grad=True)\n",
    "\n",
    "    colors = np.random.uniform(0.0, 1.0, size=(n_rects, 4))\n",
    "    colors[:, 3] = 0.95\n",
    "    colors_pre = np.arctanh(2 * colors - 1)\n",
    "    colors_pre = th.tensor(colors_pre, device=\"cuda\", dtype=th.float32, requires_grad=True)\n",
    "    colors = (th.tanh(colors_pre) + 1) * 0.5\n",
    "    \n",
    "    onion_pt = th.tensor([0.1,], dtype=th.float32, device=\"cuda\")\n",
    "\n",
    "    colored_circle_list = []\n",
    "    circle_list= []\n",
    "    for i in range(n_circles):\n",
    "        colored_circle = gls.ApplyColor2D(\n",
    "            gls.Translate2D(\n",
    "                gls.Scale2D(\n",
    "                    gls.Circle2D(circle_param[i]),\n",
    "                    circle_scale[i]),\n",
    "                circle_pos[i]), \n",
    "            colors[i])\n",
    "        colored_circle_list.append(colored_circle)\n",
    "        circle = gls.Translate2D(\n",
    "                gls.Scale2D(\n",
    "                    gls.Circle2D(circle_param[i]),\n",
    "                    circle_scale[i]),\n",
    "                circle_pos[i])\n",
    "        circle = gls.Onion2D(circle, onion_pt)\n",
    "        circle_list.append(circle)\n",
    "    param_list = [circle_param, circle_scale, circle_pos, colors_pre]\n",
    "    return colored_circle_list, circle_list, param_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter a set of colored cubes and optimize their positions\n",
    "# to match a target image.\n",
    "all_circles = []\n",
    "all_colored_circles = []\n",
    "\n",
    "onion_pt = th.tensor([0.1,], dtype=th.float32, device=\"cuda\")\n",
    "param_list = []\n",
    "for cur_layer in range(n_layers):\n",
    "    new_colored_circles, new_circles, new_params = generate_random_circles(n_prim_per_layer)\n",
    "    all_circles.extend(new_circles)\n",
    "    all_colored_circles.extend(new_colored_circles)\n",
    "    if not param_list:\n",
    "        param_list = new_params\n",
    "    else:\n",
    "        for ind, param in enumerate(param_list):\n",
    "            param_list[ind] = th.tensor(param.detach().cpu().numpy(), device=\"cuda\", dtype=th.float32, requires_grad=False)\n",
    "        param_list.extend(new_params)\n",
    "    colored_expr = gls.SourceOverSequence(*all_colored_circles)\n",
    "    sdf_expr = gls.Union(*all_circles)\n",
    "    # break\n",
    "    saturated = False\n",
    "    optim = th.optim.Adam(param_list[-4:], lr=lr)\n",
    "    while(not saturated):\n",
    "        # TODO: Make this elastic\n",
    "        for i in range(n_iters):\n",
    "        # for i in range(200):\n",
    "            optim.zero_grad()\n",
    "            # unpack tensor_points\n",
    "            # creating the list of tensors\n",
    "            tensor_list = []\n",
    "            colors_pre = param_list[-1]\n",
    "            colors = (th.tanh(colors_pre) + 1)\n",
    "            colors[:, :-1] = colors[:, :-1] * 0.5\n",
    "            colors[:, -1] = colors[:, -1] * (0.40 + alpha_range[i])\n",
    "\n",
    "            # t_ps = th.tanh(primal_points)\n",
    "            tensor_list = colored_expr.gather_tensor_list()\n",
    "            limit = 4 * n_prim_per_layer * (cur_layer)\n",
    "            tensor_list = tensor_list[:limit]\n",
    "            tensor_list = [x.detach() for x in tensor_list]\n",
    "            for ind in range(n_prim_per_layer):\n",
    "                tensor_list.append(param_list[-4][ind])\n",
    "                tensor_list.append(param_list[-3][ind])\n",
    "                tensor_list.append(param_list[-2][ind])\n",
    "                tensor_list.append(colors[ind])\n",
    "            cur_color_expr = colored_expr.inject_tensor_list(tensor_list)\n",
    "            cur_t_val = t_vals[i]\n",
    "            color_out = recursive_evaluate(cur_color_expr, sketcher_2d, \n",
    "                                            relaxed_occupancy=True,\n",
    "                                            relax_temperature= cur_t_val,)\n",
    "            color_diff = color_out - target\n",
    "            color_diff = th.norm(color_diff, dim=-1)\n",
    "            # Now this should be summed with sdf loss\n",
    "\n",
    "            tensor_list = sdf_expr.gather_tensor_list()\n",
    "            limit = 4 * n_prim_per_layer * (cur_layer)\n",
    "            tensor_list = [x.detach() for x in tensor_list[:limit]]\n",
    "            for ind in range(n_prim_per_layer):\n",
    "                tensor_list.append(param_list[-4][ind])\n",
    "                tensor_list.append(param_list[-3][ind])\n",
    "                tensor_list.append(param_list[-2][ind])\n",
    "                tensor_list.append(onion_pt)\n",
    "            cur_expr = sdf_expr.inject_tensor_list(tensor_list)\n",
    "            sdf_out = expr_to_sdf(cur_expr, sketcher_2d)\n",
    "            # print(sdf_out.min(), sdf_out.max())\n",
    "            # dist_weight = th.logical_and(-0.1<=sdf_out, sdf_out <=0).float()\n",
    "            dist_weight = (sdf_out <=0).float()\n",
    "            # dist_weight = th.nn.functional.relu(TAU - th.abs(sdf_out))\n",
    "            dist_weight = dist_weight# /(dist_weight.sum() + 1e-4)\n",
    "            dist_weight = dist_weight.detach()\n",
    "            # Drop points stochastically\n",
    "            # point_overlap_loss = compute_point_overlap_loss(rect_pos)\n",
    "            # color_diff = th.nn.functional.dropout(color_diff, p=0.1, training=True)\n",
    "            color_loss = th.sum(color_diff * dist_weight)\n",
    "            # color_loss = th.sum(color_diff)\n",
    "            # Add a loss for lines endpoints not overlapping to 0?\n",
    "            # point_overlap_loss = compute_point_overlap_loss(tensor_points)\n",
    "            loss = color_loss # + point_overlap_loss * point_spread_loss_wt\n",
    "            loss.backward()\n",
    "            # colors.grad[:, -1] = 0\n",
    "            optim.step()\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Color Loss: {color_loss.item()}, iter: {i}\")\n",
    "        saturated = True\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colored_canvas = recursive_evaluate(cur_color_expr, sketcher_2d)\n",
    "colored_canvas = colored_canvas.reshape(resolution, resolution, 4).detach().cpu().numpy()\n",
    "sdf = recursive_evaluate(cur_expr, sketcher_2d)\n",
    "sdf = sdf.reshape(resolution, resolution).detach().cpu().numpy()\n",
    "target_disp = target.reshape(resolution, resolution, 4).detach().cpu().numpy()\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(colored_canvas)\n",
    "plt.axis('off')\n",
    "plt.title(\"Optimized Execution\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(sdf)\n",
    "plt.axis('off')\n",
    "plt.title(\"Optimized SDF\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(target_disp)\n",
    "plt.title(\"Target\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/2206.04655.pdf\n",
    "# https://openaccess.thecvf.com/content/CVPR2023/papers/Jain_VectorFusion_Text-to-SVG_by_Abstracting_Pixel-Based_Diffusion_Models_CVPR_2023_paper.pdf\n",
    "# Initialization\n",
    "# UDF Loss and Xing Loss\n",
    "# Updates.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
