{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling Expressions\n",
    "\n",
    "A key benefit of having a programmatic representations of shapes is the ability use static analysis to optimize how the program is executed. This notebooks shows how we use expression compilation to speed up execution of batches of GeoLIPI expressions by an order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch as th\n",
    "import inspect\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import _pickle as cPickle\n",
    "\n",
    "import geolipi.symbolic as gls\n",
    "from geolipi.torch_compute import Sketcher, expr_to_sdf, recursive_evaluate\n",
    "# from geolipi.torch_compute import create_compiled_expr, create_evaluation_batches, batch_evaluate\n",
    "from geolipi.torch_compute.compile_expression import create_compiled_expr\n",
    "from geolipi.torch_compute.batch_evaluate_sdf import create_evaluation_batches, batch_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sketcher keeps track of some tensor device and resolution\n",
    "resolution = 64\n",
    "sketcher = Sketcher(device=\"cuda\", resolution=resolution, n_dims=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5120 expressions\n"
     ]
    }
   ],
   "source": [
    "# Load a bunch of example programs\n",
    "# Programs are saved in string format, and we use python's eval to convert them to a gls expressions\n",
    "# NOTE - it can be dangerous to use eval on strings you don't trust.\n",
    "all_functions = []\n",
    "\n",
    "str_to_cmd_mapper = gls.get_cmd_mapper()\n",
    "str_to_cmd_mapper['tensor'] = th.tensor\n",
    "\n",
    "file_name = \"../assets/example_random_programs.pkl\"\n",
    "with open(file_name, 'rb') as f:\n",
    "    expressions = cPickle.load(f)\n",
    "expressions = [eval(p, str_to_cmd_mapper) for p in expressions]\n",
    "random.shuffle(expressions)\n",
    "print(f\"Loaded {len(expressions)} expressions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 7.176399230957031e-05 seconds to run 0 programs\n",
      "Took 8.823237895965576 seconds to run 1000 programs\n",
      "Took 17.36352300643921 seconds to run 2000 programs\n",
      "Took 25.824536561965942 seconds to run 3000 programs\n",
      "Took 34.41025185585022 seconds to run 4000 programs\n",
      "Took 43.108124017715454 seconds to run 5000 programs\n",
      "Naive recursive execution time:  44.037843227386475\n"
     ]
    }
   ],
   "source": [
    "# Naive recursive execution:\n",
    "# Supports all the gls expressions, but slow.\n",
    "start_time = time.time()\n",
    "for ind, expression in enumerate(expressions):\n",
    "    if ind % 1000 == 0:\n",
    "        print(f\"Took {time.time() - start_time} seconds to run {ind} programs\")\n",
    "    cuda_expression = expression.cuda()\n",
    "    sdf = recursive_evaluate(cuda_expression, sketcher)\n",
    "end_time = time.time()\n",
    "print(\"Naive recursive execution time: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 4.5299530029296875e-05 seconds to run 0 programs\n",
      "Took 8.583478212356567 seconds to run 1000 programs\n",
      "Took 16.980957508087158 seconds to run 2000 programs\n",
      "Took 25.22557306289673 seconds to run 3000 programs\n",
      "Took 33.60206961631775 seconds to run 4000 programs\n",
      "Took 42.07800793647766 seconds to run 5000 programs\n",
      "Simple iterative execution time:  42.96791124343872\n"
     ]
    }
   ],
   "source": [
    "# expr_to_sdf uses stack based parsing to avoid recursion.\n",
    "# but DOES NOT support higher level primitives, and some of the transforms (it only keeps track of the affine transform matrix not coords)\n",
    "start_time = time.time()\n",
    "for ind, expression in enumerate(expressions):\n",
    "    if ind % 1000 == 0:\n",
    "        print(f\"Took {time.time() - start_time} seconds to run {ind} programs\")\n",
    "    cuda_expression = expression.cuda()\n",
    "    sdf = expr_to_sdf(cuda_expression, sketcher)\n",
    "end_time = time.time()\n",
    "print(\"Simple iterative execution time: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.6157186031341553 seconds to run 0 batches of size 64\n",
      "Took 5.344455718994141 seconds to run 10 batches of size 64\n",
      "Took 10.854475736618042 seconds to run 20 batches of size 64\n",
      "Took 16.030340433120728 seconds to run 30 batches of size 64\n",
      "Took 20.73273468017578 seconds to run 40 batches of size 64\n",
      "Took 25.84080982208252 seconds to run 50 batches of size 64\n",
      "Took 31.261850357055664 seconds to run 60 batches of size 64\n",
      "Took 35.96721577644348 seconds to run 70 batches of size 64\n",
      "Batched execution time:  40.16727304458618\n"
     ]
    }
   ],
   "source": [
    "# Second way is to use batching. Even including batching time, this is often slightly faster.\n",
    "# first for each expression, we need to convert it into a compiled form\n",
    "# Lets do it in batches of 256\n",
    "batch_size = 64\n",
    "n_batches = int(np.ceil(len(expressions) / batch_size))\n",
    "start_time = time.time()\n",
    "for cur_batch in range(n_batches):\n",
    "    cur_expressions = expressions[cur_batch * batch_size : (cur_batch + 1) * batch_size]\n",
    "    eval_stack = []\n",
    "    for expr in cur_expressions:\n",
    "        cuda_expr = expr.cuda()\n",
    "        expr, transforms, inversions, params = create_compiled_expr(cuda_expr, sketcher, convert_to_cpu=False)\n",
    "        eval_stack.append([expr, transforms, inversions, params])\n",
    "\n",
    "    eval_batches = create_evaluation_batches(eval_stack, convert_to_cuda=False)\n",
    "    all_sdfs = batch_evaluate(eval_batches, sketcher)\n",
    "    \n",
    "    if cur_batch % 10 == 0:\n",
    "        print(f\"Took {time.time() - start_time} seconds to run {cur_batch} batches of size {batch_size}\")\n",
    "end_time = time.time()\n",
    "print(\"Batched execution time: \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.0070345401763916016 seconds to compile 0 programs\n",
      "Took 6.822115898132324 seconds to compile 1000 programs\n",
      "Took 13.309079885482788 seconds to compile 2000 programs\n",
      "Took 19.822893619537354 seconds to compile 3000 programs\n",
      "Took 26.366687297821045 seconds to compile 4000 programs\n",
      "Took 32.809659004211426 seconds to compile 5000 programs\n",
      "Compilation time:  33.46465611457825\n",
      "Took 0.06953549385070801 seconds to run 0 batches of size 64\n",
      "Took 0.8522241115570068 seconds to run 10 batches of size 64\n",
      "Took 1.6405560970306396 seconds to run 20 batches of size 64\n",
      "Took 2.439478635787964 seconds to run 30 batches of size 64\n",
      "Took 3.1721460819244385 seconds to run 40 batches of size 64\n",
      "Took 4.003402471542358 seconds to run 50 batches of size 64\n",
      "Took 4.820006370544434 seconds to run 60 batches of size 64\n",
      "Took 5.565735816955566 seconds to run 70 batches of size 64\n",
      "Compiled Execution time:  6.244786500930786\n"
     ]
    }
   ],
   "source": [
    "# more importantly, we can load the compiled versions into a memory, and simply load and execute them when required.\n",
    "# This can speed up the execution time by a lot, especially when there are many programs to execute.\n",
    "# This version of compile + execute is integrated in the code base for [CoReF]().\n",
    "# Second way is to use batching. Even including batching time, this is often slightly faster.\n",
    "# first for each expression, we need to convert it into a compiled form\n",
    "# Lets do it in batches of 256\n",
    "batch_size = 64\n",
    "n_batches = int(np.ceil(len(expressions) / batch_size))\n",
    "start_time = time.time()\n",
    "eval_stack = []\n",
    "for ind, expr in enumerate(expressions):\n",
    "    cuda_expr = expr.cuda()\n",
    "    expr, transforms, inversions, params = create_compiled_expr(cuda_expr, sketcher, convert_to_cpu=True)\n",
    "    eval_stack.append([expr, transforms, inversions, params])\n",
    "\n",
    "    if ind % 1000 == 0:\n",
    "        print(f\"Took {time.time() - start_time} seconds to compile {ind} programs\")\n",
    "end_time = time.time()\n",
    "print(\"Compilation time: \", end_time - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "for cur_batch in range(n_batches):\n",
    "    cur_eval = eval_stack[cur_batch * batch_size : (cur_batch + 1) * batch_size]\n",
    "    eval_batches = create_evaluation_batches(cur_eval, convert_to_cuda=True)\n",
    "    all_sdfs = batch_evaluate(eval_batches, sketcher)\n",
    "    \n",
    "    if cur_batch % 10 == 0:\n",
    "        print(f\"Took {time.time() - start_time} seconds to run {cur_batch} batches of size {batch_size}\")\n",
    "end_time = time.time()\n",
    "print(\"Compiled Execution time: \", end_time - start_time)\n",
    "\n",
    "# This yields a significant speedup ~ 500 %. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0.06584429740905762 seconds to compile 0 programs\n",
      "Took 22.122634410858154 seconds to compile 1000 programs\n",
      "Took 40.67112684249878 seconds to compile 2000 programs\n",
      "Took 62.87722945213318 seconds to compile 3000 programs\n",
      "Took 85.7822482585907 seconds to compile 4000 programs\n",
      "Took 108.93477153778076 seconds to compile 5000 programs\n",
      "Compilation time:  110.41778016090393\n",
      "Took 0.2236177921295166 seconds to run 0 batches of size 64\n",
      "Took 3.050459861755371 seconds to run 10 batches of size 64\n",
      "Took 6.006987810134888 seconds to run 20 batches of size 64\n",
      "Took 8.54468059539795 seconds to run 30 batches of size 64\n",
      "Took 11.858993768692017 seconds to run 40 batches of size 64\n",
      "Took 14.960047006607056 seconds to run 50 batches of size 64\n",
      "Took 17.59245204925537 seconds to run 60 batches of size 64\n",
      "Took 20.26682448387146 seconds to run 70 batches of size 64\n",
      "Compiled Execution time for dnf programs:  22.381612062454224\n"
     ]
    }
   ],
   "source": [
    "# Extra (NOT RECOMMENDED) - It is also possible to convert the programs into a CNF/DNF form, and then execute them.\n",
    "# This can make all the expression have a single union, and multiple intersection operators - which can sometimes be much faster (if the intersections are batched)\n",
    "# This DNF form of expressions is used in [CSGStump]().\n",
    "\n",
    "batch_size = 64\n",
    "n_batches = int(np.ceil(len(expressions) / batch_size))\n",
    "eval_stack = []\n",
    "\n",
    "start_time = time.time()\n",
    "for ind, expr in enumerate(expressions):\n",
    "    cuda_expr = expr.cuda()\n",
    "    expr, transforms, inversions, params = create_compiled_expr(cuda_expr, sketcher, convert_to_cpu=True, resolve_to_dnf=True)\n",
    "    eval_stack.append([expr, transforms, inversions, params])\n",
    "\n",
    "    if ind % 1000 == 0:\n",
    "        print(f\"Took {time.time() - start_time} seconds to compile {ind} programs\")\n",
    "end_time = time.time()\n",
    "print(\"Compilation time: \", end_time - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "for cur_batch in range(n_batches):\n",
    "    cur_eval = eval_stack[cur_batch * batch_size : (cur_batch + 1) * batch_size]\n",
    "    eval_batches = create_evaluation_batches(cur_eval, convert_to_cuda=True)\n",
    "    all_sdfs = batch_evaluate(eval_batches, sketcher)\n",
    "    \n",
    "    if cur_batch % 10 == 0:\n",
    "        print(f\"Took {time.time() - start_time} seconds to run {cur_batch} batches of size {batch_size}\")\n",
    "end_time = time.time()\n",
    "print(\"Compiled Execution time for dnf programs: \", end_time - start_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfrl2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
